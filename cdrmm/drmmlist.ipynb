{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = 'data/'\n",
    "# this is annoying... but this is how Conv2D layer in Keras works!\n",
    "#A matrix is treated a grayscale image, i.e. am image with num_channels = 1\n",
    "NUMCHANNELS = 1\n",
    "\n",
    "class InteractionData:\n",
    "    #Interaction data of query qid with K top docs -\n",
    "    #each row vector is a hisotgram of interaction data for a document\n",
    "    def __init__(self, qid, dataPathBase=DATADIR):\n",
    "        self.qid = qid        \n",
    "        dataFile = \"{}/{}.txt\".format(dataPathBase, self.qid)        \n",
    "        df = pd.read_csv(dataFile, delim_whitespace=True, header=None)\n",
    "        self.matrix = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedInstance:\n",
    "    def __init__(self, line):\n",
    "        l = line.strip().split('\\t')        \n",
    "        self.id_a = l[0]\n",
    "        self.id_b = l[1]\n",
    "        self.label = int(l[2])\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"({}, {})\".format(self.id_a, self.id_b)\n",
    "    \n",
    "    def getKey(self):\n",
    "        return \"{}-{}\".format(self.id_a, self.id_b)\n",
    "                    \n",
    "#Separate instances for training/test sets etc. Load only the id pairs.\n",
    "#Data is loaded later in batches with a subclass of Keras generator\n",
    "class PairedInstanceIds:    \n",
    "    '''\n",
    "    Each line in this file should comprise three tab separated fields\n",
    "    <id1> <id2> <label (1/0)>\n",
    "    '''\n",
    "    def __init__(self, idpairLabelsFile):\n",
    "        self.data = {}\n",
    "\n",
    "        with open(idpairLabelsFile) as f:\n",
    "            content = f.readlines()\n",
    "        \n",
    "        # remove whitespace characters like `\\n` at the end of each line\n",
    "        for x in content:\n",
    "            instance = PairedInstance(x)\n",
    "            self.data[instance.getKey()] = instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3960/4950 pairs for training\n"
     ]
    }
   ],
   "source": [
    "allPairs = PairedInstanceIds(\"data/pairs.txt\")\n",
    "allPairsList = list(allPairs.data.values())\n",
    "np.random.shuffle(allPairsList)\n",
    "num_pairs = len(allPairsList)\n",
    "\n",
    "TRAIN_RATIO=0.8\n",
    "num_training = int(TRAIN_RATIO*num_pairs)\n",
    "\n",
    "#get the ids\n",
    "train_pairs = allPairsList[0:num_training]\n",
    "test_pairs = allPairsList[num_training:]\n",
    "\n",
    "print ('{}/{} pairs for training'.format(num_training, num_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num top docs (Default: 10)\n",
    "K=10\n",
    "#M: bin-size (Default: 20)\n",
    "M=20\n",
    "BATCH_SIZE=20\n",
    "\n",
    "'''\n",
    "The files need to be residing in the folder data/\n",
    "Each file is a matrix of values that's read using \n",
    "'''\n",
    "class PairCmpDataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, paired_instances_ids, dataFolder=DATADIR, batch_size=BATCH_SIZE, dim=(K, M, NUMCHANNELS)):\n",
    "        'Initialization'\n",
    "        self.paired_instances_ids = paired_instances_ids\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.dataDir = dataFolder\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.paired_instances_ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs = [self.paired_instances_ids[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.__data_generation(list_IDs)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Update indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.paired_instances_ids))\n",
    "\n",
    "    def __data_generation(self, list_IDs):\n",
    "        'Generates data pairs containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = [np.empty((self.batch_size, *self.dim)) for i in range(2)]\n",
    "        Y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, paired_instance in enumerate(list_IDs):            \n",
    "            a_id = paired_instance.id_a\n",
    "            b_id = paired_instance.id_b\n",
    "            \n",
    "            #read from the data file and construct the instances\n",
    "            a_data = InteractionData(a_id, self.dataDir)\n",
    "            b_data = InteractionData(b_id, self.dataDir)\n",
    "            \n",
    "            w, h = a_data.matrix.shape\n",
    "            a_data.matrix = a_data.matrix.reshape(w, h, 1)\n",
    "            b_data.matrix = b_data.matrix.reshape(w, h, 1)\n",
    "            \n",
    "            X[0][i,] = a_data.matrix\n",
    "            X[1][i,] = b_data.matrix\n",
    "            Y[i] = paired_instance.label\n",
    "            \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras import layers\n",
    "HIDDEN_LAYER_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese(input_shape):\n",
    "    \n",
    "    input_a = Input(shape=input_shape, dtype='float32')\n",
    "    input_b = Input(shape=input_shape, dtype='float32')\n",
    "\n",
    "    matrix_encoder = Sequential()\n",
    "    matrix_encoder.add(Conv2D(32, (5,5), activation='relu', input_shape=input_shape))\n",
    "    matrix_encoder.add(MaxPooling2D(padding='same'))\n",
    "    matrix_encoder.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    matrix_encoder.add(MaxPooling2D(padding='same'))\n",
    "    matrix_encoder.add(Flatten())\n",
    "    matrix_encoder.add(Dropout(0.2))\n",
    "    matrix_encoder.add(Dense(HIDDEN_LAYER_DIM, activation='sigmoid'))    \n",
    "\n",
    "    encoded_a = matrix_encoder(input_a)\n",
    "    encoded_b = matrix_encoder(input_b)\n",
    "\n",
    "    merged_vector = concatenate([encoded_a, encoded_b], axis=-1)\n",
    "    \n",
    "    # And add a logistic regression (2 class - sigmoid) on top\n",
    "    # used for backpropagating from the (pred, true) labels\n",
    "    predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "    siamese_net = Model([input_a, input_b], outputs=predictions)\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 20, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10, 20, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 16)           22416       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 22,449\n",
      "Trainable params: 22,449\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = build_siamese((K, M, 1))\n",
    "siamese_model.compile(loss = keras.losses.BinaryCrossentropy(), optimizer = keras.optimizers.Adam())\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "198/198 [==============================] - 6s 30ms/step - loss: 0.7028\n",
      "Epoch 2/3\n",
      "198/198 [==============================] - 5s 27ms/step - loss: 0.6957\n",
      "Epoch 3/3\n",
      "Epoch 2/3\n",
      "198/198 [==============================] - 5s 28ms/step - loss: 0.6942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64718d320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS=3\n",
    "training_generator = PairCmpDataGenerator(train_pairs, dataFolder=DATADIR)\n",
    "siamese_model.fit_generator(generator=training_generator,\n",
    "                    use_multiprocessing=True, epochs=EPOCHS, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
